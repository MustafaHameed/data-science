Week 1
-------------------------
Free data resource:
    - mySQL
    - MangoDB
    - Open Baltimore

Goal of this course:
Raw data -> Processing script -> tidy data -> data analysis -> data communication

Definition of Data:
-------------------
Data are values of qualitative or quantitative variables, belonging to a set of
items.
Qualitative: Country of origin, sex, treatment
Quantitative:Height, weight, blood pressure

Raw versus processed data:
--------------------------
Raw data:
    - the origin source of the data
    - often hard to use for data analysis
    - data analysis includes processing
    - raw data may only need to be processed once
Processed data:
    - data that is ready for analysis
    - processing can include merging, subsetting, transforming, etc.
    - there may be standards for processing
    - all steps should be recorded

The information you should pass to a statistician:
    1) The raw data.
    2) A tidy data set
    3) A code book describing each variable and its values in the tidy data set.
    4) An explicit and exact recipe you used to go from 1 -> 2,3

The raw data:
-------------
Examples of the raw form of data:
    - The strange binary file your measurement machine spits out
    - The unformatted Excel file with 10 worksheets the company you contracted with sent you
    - The complicated JSON data you got from scraping the Twitter API
    - The hand-entered numbers you collected looking through a microscope
You know the raw data is in the right format if you:
    - Ran no software on the data
    - Did not manipulate any of the numbers in the data
    - You did not remove any data from the data set
    - You did not summarize the data in any way

The tidy data:
--------------
1) Each variable you measure should be in one column
2) Each observation of that variable should be in a different row
3) There should be one table for each "kind" of variable
4) If you have multiple tables, they should include a column in the table that
allows them to be linked

Some other important tips:
    - Include a row at the top of each file with variable names
    - Make variable names human readable: AgeAtDiagnosis instead of AgeDx
    - In general, data should be saved in one file per table

The code book:
--------------
1) Information about the variables (including units!) in the data set not
contained in the tidy data
2) Information about the summary choices you made
3) Information about the experimental study design you used

Some other important tips:
    - A common format for this document is a Word file.
    - There should be a section called "Study design" that has a thorough
    description of how you collected the data.
    - There is a section called "Code book" that describes each variable and its
    units.

The instruction list:
---------------------
- Ideally a computer script (in R, Python, or something else)
- The input for the script is the raw data
- The output is the processed, tidy data
- There are no parameters to the script

In some cases, it will not be possible to script every step. In that cases, you
should provide instructions like:
    1) Step 1 - take the raw file, run version 3.1.2 of summarize software with
    parameters a=1, b=2, c=3
    2) Step 2 - run the software separately for each sample
    3) Step 3 - take column three of outputfile.out for each sample and that is
    the corresponding row in the output data set

Downloading files:
------------------
Get/set your working directory:
    - getwd(), setwd()
    - relative path: setwd("./data"), setwd("../")
    - absolute path: setwd("/Uses/Github/data-science")
Checking for and creating directories:
    - file.exists("directoryName")
    - dir.create("directoryName")
Getting the data from the internet:
    - download.file()
    - important parameter: url, destfile, method
    - useful for downloading tab-delimited, csv and other files
Download a file from the web:
    > fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
    > download.file(fileUrl, destfile = "./data/cameras.csv", method = "curl")
    > list.files("./data")
    ## [1] "cameras.csv"
    > dateDownloaded <- date()
    > dateDownloaded
    ## [1] "Sun Jan 12 21:37:44 2014"
Some notes about download.file()
    - If the url starts with http you can use download.file()
    - If the url starts with https on Windows you may be ok
    - If the url starts with https on Mac you may need to set method="curl"
    - If the file is big, this might take a while
    - Be sure to record when you downloaded.

Loading files:
--------------
read.table()
    - This is the main function for reading data into R
    - Flexible and robust but requires more parameters
    - Reads the data into RAM - big data can cause problems
    - Important parameters file, header, sep, row.names, nrows
    - Related: read.csv(), read.csv2()
Example: Baltimore camera data
    > cameraData <- read.table("./data/cameras.csv", sep = ",", header = TRUE)
    > head(cameraData)
Some more important parameters
    quote - you can tell R whether there are any quoted values quote="" means no quotes.
    na.strings - set the character that represents a missing value.
    nrows - how many rows to read of the file (e.g. nrows=10 reads 10 lines).
    skip - number of lines to skip before starting to read
The possible biggest trouble with reading flat files are quotation
marks ` or " placed in data values, setting quote="" often resolves these.

Reading excel files:
--------------------
read.xlsx(), read.xlsx2() {xlsx package}
    > library(xlsx)
    > cameraData <- read.xlsx("./data/cameras.xlsx",sheetIndex=1,header=TRUE)
    > head(cameraData)
Reading specific rows and columns:
    > colIndex <- 2:3
    > rowIndex <- 1:4
    > cameraDataSubset <- read.xlsx("./data/cameras.xlsx",sheetIndex=1,
                                    colIndex=colIndex,rowIndex=rowIndex)
    > cameraDataSubset
Further notes
    - The write.xlsx function will write out an Excel file with similar arguments.
    - read.xlsx2 is much faster than read.xlsx but for reading subsets of rows
    may be slightly unstable.
    - The XLConnect package has more options for writing and manipulating Excel
    files
    - The XLConnect vignette is a good place to start for that package
    - In general it is advised to store your data in either a database or in
    comma separated files (.csv) or tab separated files (.tab/.txt) as they are
    easier to distribute.

Reading XML:
------------
XML:
    - Extensible markup language
    - Frequently used to store structured data
    - Particularly widely used in internet applications
    - Extracting XML is the basis for most web scraping
    - Components:
        Markup - labels that give the text structure
        Content - the actual text of the document

Tags, elements and attributes:
    - Tags correspond to general labels
        - Start tags <section>
        - End tags </section>
        - Empty tags <line-break />
    - Elements are specific examples of tags
        - <Greeting> Hello, world </Greeting>
    - Attributes are components of the label
        - <img src="jeff.jpg" alt="instructor"/>
        - <step number="3"> Connect A to B. </step>
Read the file into R:
    > library(XML)
    > fileUrl <- "http://www.w3schools.com/xml/simple.xml"
    > doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
    > rootNode <- xmlRoot(doc)
    > xmlName(rootNode)
    [1] "breakfast_menu"
    > names(rootNode)
      food   food   food   food   food
    "food" "food" "food" "food" "food"
Directly access parts of the XML document:
    > rootNode[[1]]
    <food>
      <name>Belgian Waffles</name>
      <price>$5.95</price>
      <description>Two of our famous Belgian Waffles with plenty of real maple syrup</description>
      <calories>650</calories>
    </food>
    > rootNode[[1]][[1]]
    <name>Belgian Waffles</name>
Programatically extract parts of the file:
    xmlSApply(rootNode,xmlValue)
                                                                                                                    food
                              "Belgian Waffles$5.95Two of our famous Belgian Waffles with plenty of real maple syrup650"
                                                                                                                    food
                   "Strawberry Belgian Waffles$7.95Light Belgian waffles covered with strawberries and whipped cream900"
                                                                                                                    food
"Berry-Berry Belgian Waffles$8.95Light Belgian waffles covered with an assortment of fresh berries and whipped cream900"
                                                                                                                    food
                                               "French Toast$4.50Thick slices made from our homemade sourdough bread600"
                                                                                                                    food
                        "Homestyle Breakfast$6.95Two eggs, bacon or sausage, toast, and our ever-popular hash browns950"
XPath:
    /node Top level node
    //node Node at any level
    node[@attr-name] Node with an attribute name
    node[@attr-name='bob'] Node with attribute name attr-name='bob'
Get the items on the menu and prices:
    > xpathSApply(rootNode,"//name",xmlValue)
    [1] "Belgian Waffles"             "Strawberry Belgian Waffles"  "Berry-Berry Belgian Waffles"
    [4] "French Toast"                "Homestyle Breakfast"
    > xpathSApply(rootNode,"//price",xmlValue)
    [1] "$5.95" "$7.95" "$8.95" "$4.50" "$6.95"
Extract content by attributes:
    > fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
    > doc <- htmlTreeParse(fileUrl,useInternal=TRUE)
    > scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
    > teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)
    > scores
     [1] "49-27"    "14-6"     "30-9"     "23-20"    "26-23"    "19-17"    "19-16"    "24-18"
     [9] "20-17 OT" "23-20 OT" "19-3"     "22-20"    "29-26"    "18-16"    "41-7"     "34-17"
    > teams
     [1] "Denver"      "Cleveland"   "Houston"     "Buffalo"     "Miami"       "Green Bay"
     [7] "Pittsburgh"  "Cleveland"   "Cincinnati"  "Chicago"     "New York"    "Pittsburgh"
    [13] "Minnesota"   "Detroit"     "New England" "Cincinnati"

Reading JSON:
-------------
JSON:
    - Javascript Object Notation
    - Lightweight data storage
    - Common format for data from application programming interfaces (APIs)
    - Similar structure to XML but different syntax/format
    - Data stored as
        - Numbers (double)
        - Strings (double quoted)
        - Boolean (true or false)
        - Array (ordered, comma separated enclosed in square brackets [])
        - Object (unorderd, comma separated collection of key:value pairs in
        curley brackets {})
Reading data from JSON {jsonlite package}
    > library(jsonlite)
    > jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
    > names(jsonData)
Nested objects in JSON:
    > names(jsonData$owner)
    > names(jsonData$owner$login)
Writing data frames to JSON:
    > myjson <- toJSON(iris, pretty=TRUE)
    > cat(myjson)
    [
        {
            "Sepal.Length" : 5.1,
            "Sepal.Width" : 3.5,
            "Petal.Length" : 1.4,
            "Petal.Width" : 0.2,
            "Species" : "setosa"
        },
        {
            "Sepal.Length" : 4.9,
            "Sepal.Width" : 3,
            "Petal.Length" : 1.4,
            "Petal.Width" : 0.2,
            "Species" : "setosa"
        },
        {
Convert back to JSON:
    > iris2 <- fromJSON(myjson)
    > head(iris2)
      Sepal.Length Sepal.Width Petal.Length Petal.Width Species
    1          5.1         3.5          1.4         0.2  setosa
    2          4.9         3.0          1.4         0.2  setosa
    3          4.7         3.2          1.3         0.2  setosa
    4          4.6         3.1          1.5         0.2  setosa
    5          5.0         3.6          1.4         0.2  setosa
    6          5.4         3.9          1.7         0.4  setosa

data.table Package:
-------------------
data.table
    - Inherets from data.frame
        - All functions that accept data.frame work on data.table
    - Written in C so it is much faster
    - Much, much faster at subsetting, group, and updating
Create data tables just like data frames:
    > library(data.table)
    > DF = data.frame(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
    > head(DF,3)
           x y        z
    1 0.4159 a -0.05855
    2 0.8433 a  0.13732
    3 1.0585 a  2.16448
    > DT = data.table(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
    > head(DT,3)
              x y      z
    1: -0.27721 a 0.2530
    2:  1.00158 a 1.5093
    3: -0.03382 a 0.4844
See all the data tables in memory:
    > tables()
         NAME NROW MB COLS  KEY
    [1,] DT      9 1  x,y,z
    Total: 1MB
Subsetting rows:
    > DT[2,]
           x y     z
    1: 1.002 a 1.509
    > DT[DT$y=="a",]
              x y      z
    1: -0.27721 a 0.2530
    2:  1.00158 a 1.5093
    3: -0.03382 a 0.4844
    > DT[c(2,3)]
              x y      z
    1:  1.00158 a 1.5093
    2: -0.03382 a 0.4844
Column subsetting in data.table:
    - The subsetting function is modified for data.table
    - The argument you pass after the comma is called an "expression"
    - In R an expression is a collection of statements enclosed in curley brackets
    {
      x = 1
      y = 2
    }
    k = {print(10); 5}
    [1] 10
    print(k)
    [1] 5
Calculating values for variables with expressions:
    DT[,list(mean(x),sum(z))]
            V1     V2
    1: 0.05637 0.5815
    DT[,table(y)]
    y
    a b c
    3 3 3
Adding new columns:
    DT[,w:=z^2]
              x y        z        w
    1: -0.27721 a  0.25300 0.064009
    2:  1.00158 a  1.50933 2.278091
    3: -0.03382 a  0.48437 0.234619
    4: -0.70493 b -1.22755 1.506885
    5: -1.36402 b -0.64624 0.417631
    6: -0.26224 b -0.51427 0.264475
    7: -0.10929 c  1.21445 1.474901
    8:  1.40234 c  0.07493 0.005614
    9:  0.85494 c -0.56652 0.320948
Multiple operations
    DT[,m:= {tmp <- (x+z); log2(tmp+5)}]
              x y        z        w     m
    1: -0.27721 2  0.25300 0.064009 2.315
    2:  1.00158 2  1.50933 2.278091 2.909
    3: -0.03382 2  0.48437 0.234619 2.446
    4: -0.70493 2 -1.22755 1.506885 1.617
    5: -1.36402 2 -0.64624 0.417631 1.580
    6: -0.26224 2 -0.51427 0.264475 2.078
    7: -0.10929 2  1.21445 1.474901 2.610
    8:  1.40234 2  0.07493 0.005614 2.695
    9:  0.85494 2 -0.56652 0.320948 2.403
plyr like operations:
    DT[,a:=x>0]
              x y        z        w     m     a
    1: -0.27721 2  0.25300 0.064009 2.315 FALSE
    2:  1.00158 2  1.50933 2.278091 2.909  TRUE
    3: -0.03382 2  0.48437 0.234619 2.446 FALSE
    4: -0.70493 2 -1.22755 1.506885 1.617 FALSE
    5: -1.36402 2 -0.64624 0.417631 1.580 FALSE
    6: -0.26224 2 -0.51427 0.264475 2.078 FALSE
    7: -0.10929 2  1.21445 1.474901 2.610 FALSE
    8:  1.40234 2  0.07493 0.005614 2.695  TRUE
    9:  0.85494 2 -0.56652 0.320948 2.403  TRUE
    DT[,b:= mean(x+w),by=a]
              x y        z        w     m     a      b
    1: -0.27721 2  0.25300 0.064009 2.315 FALSE 0.2018
    2:  1.00158 2  1.50933 2.278091 2.909  TRUE 1.9545
    3: -0.03382 2  0.48437 0.234619 2.446 FALSE 0.2018
    4: -0.70493 2 -1.22755 1.506885 1.617 FALSE 0.2018
    5: -1.36402 2 -0.64624 0.417631 1.580 FALSE 0.2018
    6: -0.26224 2 -0.51427 0.264475 2.078 FALSE 0.2018
    7: -0.10929 2  1.21445 1.474901 2.610 FALSE 0.2018
    8:  1.40234 2  0.07493 0.005614 2.695  TRUE 1.9545
    9:  0.85494 2 -0.56652 0.320948 2.403  TRUE 1.9545
Special variables:
    .N An integer, length 1, containing the numbe r
        set.seed(123);
        DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
        DT[, .N, by=x]
           x     N
        1: a 33387
        2: c 33201
        3: b 33412
Keys:
    > DT <- data.table(x=rep(c("a","b","c"),each=100), y=rnorm(300))
    > setkey(DT, x)
    > DT['a']
         x        y
      1: a  0.25959
      2: a  0.91751
      3: a -0.72232
      4: a -0.80828
      5: a -0.14135
      6: a  2.25701
      7: a -2.37955
      8: a -0.45425
      9: a -0.06007
     10: a  0.86090
     11: a -1.78466
     12: a -0.13074
     13: a -0.36984
     14: a -0.18066
Joins:
    DT1 <- data.table(x=c('a', 'a', 'b', 'dt1'), y=1:4)
    DT2 <- data.table(x=c('a', 'b', 'dt2'), z=5:7)
    setkey(DT1, x); setkey(DT2, x)
    merge(DT1, DT2)
       x y z
    1: a 1 5
    2: a 2 5
    3: b 3 6
Fast reading:
    > big_df <- data.frame(x=rnorm(1E6), y=rnorm(1E6))
    > file <- tempfile()
    > write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep="\t", quote=FALSE)
    > system.time(fread(file))
       user  system elapsed
      0.312   0.015   0.326
    > system.time(read.table(file, header=TRUE, sep="\t"))
       user  system elapsed
      5.702   0.048   5.755
